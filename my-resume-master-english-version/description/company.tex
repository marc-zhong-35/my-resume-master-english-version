\resheading{Work experience }
  \begin{itemize}[leftmargin=*]
    \item
           \ressubsingleline{HSBC Technology}{Data science}{2022.07- 2023.03}
           {\small
      \begin{itemize}
      \item I participate in the money laundering prevention prediction project.\\This project mainly uses the user's transfer and consumption characteristics,builds a deep learning\\ pipeline through tensorflow to predict the user's risk level offline and output the dashboard of risky \\user characteristics.
	  
            \end{itemize}
}


    \item
           \ressubsingleline{iPinyou.inc}{Machine learning engineer}{2021.02- 2022.06}
           {\small
      \begin{itemize}
      \item I bulid the pipeline for  data prepation using the hive and sqooop tools.
      \item I use python to build the machine learning pipeline for the the rebuy problem of car,including feature engnieering and model train and optimize.
	  \item I work with the aispeech inc to build the ASR(audio speech recognization) pipeline(use python and linux shell) to recognize the audio and analyze the result file. 
            \end{itemize}

             }
    
 \end{itemize}
    
 \resheading{Intern experience }
  \begin{itemize}[leftmargin=*]   
        \item
           \ressubsingleline{TCL Industrial  research lab }{Data mining intern}{2020.07-2020.09}
           {\small
      \begin{itemize}
      \item I participated in the formulation of the business indicators of the recommendation \\ system CTR through discussions with members of the group, and conducted statistical analysis \\based on the above indicators.
         \item I use spark to complete data cleaning and verification of abnormal data.
          \item I participate in the recommendation strategy discussion within the group, and participate in the classification of large-scale feature data (Random Fourier features SVM), clustering (minitach kmeans), \\ and participate in feature selection and feature crossover work.
           \item I participate in the daily maintenance of the crawler code in the group to enrich my own data mining experience.

            \end{itemize}

             }
     \item
        \ressubsingleline{AIATSS}{Data analysis intern}{2020.04-2020.6}
        {\small
      \begin{itemize}
      \item I write SQL and python scripts to check the company's data.
        \item I use jira to monitor the progress of the workflow in real time, and draw a report on \\the progress of  the test in the group through the Excel pivot table.
         \item I have a deeper understanding of the testing process and the ETL development proces
         
       \end{itemize}
       }
             
  \end{itemize}

\resheading{Project experience }
  \begin{itemize}[leftmargin=*]
    \item
      \ressubsingleline{2017 MCM/ICM}{Captain}{2017.02}
      {\small
      \begin{itemize}
      \item We use the analytic hierarchy process to carry out statistical analysis on the factors affecting \\the urban living environment, and at the same time analyze the factors affecting the urban \\living environment and the weight of the factors.
        \item We use fuzzy comprehensive evaluation and gray prediction methods to predict the changes of \\various indicators.
        \item We study urban sustainable development models, and after joint discussions within the group, \\we write the sustainable development papers to describe changes in various indicators.
      \end{itemize}
      }
    
    \item
      \ressubsingleline{TaiDi competition}{Captain}{2018.03 -- 2018.04}
      {\small
      \begin{itemize}
        \item Firstly,we cleaned the original data set and used regular expressions to extract the names of \\TV programs in the original data and categorized the programs. We also implicitly score\\ TV programs based on the user's viewing time and frequency.
        \item Secondly,we constructed a user label system table and a product label system table, and \\performed user portraits based on the time characteristics of user viewing information and we \\matched programs and program categories
to categorize the TV programs.
        \item  To better implement the recommendation, we use  user-base collaborative filtering, item-base \\collaborative filtering, SVD and hybrid Recommendation algorithm.The SVD algorithm\\ has the best effect.
		\item We use K-means method to package users and products, and recommend users without any \\ historical behavior, effectively solving the problems of user cold start and product cold start.
        \item After the competition, we optimized the original method and tried to use Text-cnn to recommend \\the original data , which improved the accuracy of the recommendation.
      \end{itemize}
      }
    \item
      \ressubsingleline{Douban web crawler data analysis}{Personal project}{2019.09 – 2019.12}
      {\small
      \begin{itemize}
       \item Project website:https://github.com/W55699/doubanbook − web − crawler
       \item I use regular expressions, and by creating a thread pool,\\ multi-threaded to crawl Douban books information
       \item I converted the information obtained by the crawler into csv file\\ and stored it in the mysql database.
       \item I use pandas to read csv, and do data visualization analysis and statistical analysis.
       \item I use pca to reduce the dimensionality of the data, extract key information, and then use\\ the k-means algorithm to mine similar types of book information.
       \item I divided the data into training set and test set based on the information after reducing dimension, combined with the label of the data, and divided the data into two categories, and compared the\\ pros and cons of various classification methods such as SVM, LR, decision tree, and random forest\\ algorithm.
      \end{itemize}
      }
    \item
      \ressubsingleline{IMDB sentiment analysis}{Personal project}{2020.10 – 2020.12}
      {\small
      \begin{itemize}
      
       \item I use stop-words to clean the data set and use wordcloud to visualize the keyword. 	
       \item I use word2vec to vectorize the text.
       \item I used the bi-lstm model to classify comments with different emotions, and trained the model, \\and the accuracy of the model reached 85\% in the test set. 
       \item I use docker, Tensorflow-serving, and streamlit to deploy the model on the web and complete the visualization of the model.
      \end{itemize}
      }
    \item
      \ressubsingleline{IMDB sentiment analysis}{Personal project}{2020.10 – 2020.12}
      {\small
      \begin{itemize}
      
       \item I use stop-words to clean the data set and use wordcloud to visualize the keyword. 	
       \item I use word2vec to vectorize the text.
       \item I used the bi-lstm model to classify comments with different emotions, and trained the model, \\and the accuracy of the model reached 85\% in the test set. 
       \item I use docker, Tensorflow-serving, and streamlit to deploy the model on the web and complete the visualization of the model.
      \end{itemize}
      }
    \item
      \ressubsingleline{IMDB sentiment analysis}{Personal project}{2020.10 – 2020.12}
      {\small
      \begin{itemize}
      
       \item I use stop-words to clean the data set and use wordcloud to visualize the keyword. 	
       \item I use word2vec to vectorize the text.
       \item I used the bi-lstm model to classify comments with different emotions, and trained the model, \\and the accuracy of the model reached 85\% in the test set. 
       \item I use docker, Tensorflow-serving, and streamlit to deploy the model on the web and complete the visualization of the model.
      \end{itemize}
      }
    \item
      \ressubsingleline{GHAC car repurchase machine learning project}{Ipinyou.inc}{2021.02 – 2022.06}
      {\small
      \begin{itemize}
       \item The project mainly uses the characteristics of vehicle repairs and the characteristics of car owners on the official Weibo and WeChat to recommend car owners to repurchase.
       \item Data preprocessing: Import data from database to Hive using sqoop. Then use hive SQL to preprocess the data (data cleaning and defining positive and negative samples)
       \item Machine learning model training and prediction: use pandas to import data and do feature engineering. Then we use catboost, xgboost, logistic regression model to train the model and predict. At the same time, we adjust the output weights of each model based on the feedback we get.
       \item Data output: Combined with business logic filtering, the top 0.5\% prediction results of the model are output to the output database, and finally the ETL team sends the data to each 4s store. The ETL team will transfer these data to the 4S store to call customers for redemption promotion.
      \end{itemize}
      }
    \item
      \ressubsingleline{Credit card financial risk analysis}{HSBC}{2022.07 – 2023.02}
      {\small
      \begin{itemize}
      
       \item This project mainly uses user characteristics and consumption characteristics to conduct risk ratings for HSBC credit cards.
       \item Data preprocessing: use python, hive, and shell scripts to clean financial data, and use jenkins and git to manage CI/CD codes.
       \item Data modeling: Use python to perform feature engineering on the data on the gcp platform, use tensorflow to build a tabnet model for prediction, and compare it with LR and Xgboost models.
       \item Model output: output 1\% of the highest risk users, and use seaborn to visualize their characteristics.
      \end{itemize}
      }




     \end{itemize}
















